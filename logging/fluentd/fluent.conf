<source>
  @type forward      # Используем in_forward плагин для приема логов (https://docs.fluentd.org/v0.12/articles/in_forward)
  port 24224
  bind 0.0.0.0
</source>

<filter service.ui>
  @type parser
  <parse>
    @type grok
    <grok>
      pattern %{RUBY_LOGGER}
      #grok_pattern %{RUBY_LOGGER}
    </grok>
  </parse>
  key_name log
</filter>

<filter service.ui>
  @type parser
  <parse>
    @type grok
    <grok>
      pattern service=%{WORD:service} \| event=%{WORD:event} \| request_id=%{GREEDYDATA:request_id} \| message='%{GREEDYDATA:message}'
    </grok>
  </parse>
  key_name message
  reserve_data true
</filter>

<filter service.ui>
  @type parser
  <parse>
    @type grok
    <grok>
      pattern service=%{WORD:service} \| event=%{WORD:event} \| path=%{GREEDYDATA:path} \| request_id=%{GREEDYDATA:request_id} \| remote_addr=%{IPV4:remote_addr} \| method= %{WORD:method} \| response_status=%{INT:response_status}
    </grok>
  </parse>
  key_name message
</filter>


<match *.**>
  @type copy        # Используем copy плагин, чтобы переправить все входящие логи в ElasticSearch, а также вывести в output (https://docs.fluentd.org/v0.12/articles/out_copy)
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    logstash_format true
    logstash_prefix fluentd
    logstash_dateformat %Y%m%d
    include_tag_key true
    type_name access_log
    tag_key @log_name
    flush_interval 1s
  </store>
  <store>
    @type stdout
  </store>
</match>
